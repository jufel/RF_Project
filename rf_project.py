# -*- coding: utf-8 -*-
"""RF_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XrHmYfz_vPLUKiQQr_he67Xkalav2kaA
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pprint
# %tensorflow_version 1.x
import tensorflow as tf

if 'COLAB_TPU_ADDR' not in os.environ:
  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')
else:
  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
  print ('TPU address is', tpu_address)

  with tf.Session(tpu_address) as session:
    devices = session.list_devices()
    
  print('TPU devices:')
  pprint.pprint(devices)

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals

try:
  # The %tensorflow_version magic only works in colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

import os
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf

from tensorflow import keras as keras

import cv2

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/My\ Drive/Project_Data

print(len(os.listdir('/content/drive/My Drive/Project_Data/Group_running')))

DataDir = "/content/drive/My Drive/Project_Data"
CATEGORIES = ["Wheeled","Truck","Clutter","Oneperson_walking","Oneperson_crawling","Oneperson_running","Group_walking","Group_running"]

for category in CATEGORIES:
    path = os.path.join(DataDir,category)
    for img in os.listdir(path):
        imgarray=cv2.imread(os.path.join(path,img))
        b,g,r = cv2.split(imgarray)       # get b,g,r
        rgb_img = cv2.merge([r,g,b])
        plt.imshow(rgb_img, cmap="gray")
        plt.show()
        break
    break
    
   # b,g,r = cv2.split(bgr_img)       # get b,g,r
    #    rgb_img = cv2.merge([r,g,b])

print(rgb_img.shape)

img_size = 500

new_array=cv2.resize(rgb_img,(img_size,img_size))
plt.imshow(new_array,cmap='gray')
plt.show()

training_data=[]

def create_train_data():
    j = 0 ;
    print(j)
    for category in CATEGORIES:
        path = os.path.join(DataDir,category)
        class_num = CATEGORIES.index(category)
        for img in os.listdir(path):
            try:
                print("j1 = ", j)
                imgarray=cv2.imread(os.path.join(path,img))
                b,g,r = cv2.split(imgarray)       # get b,g,r
                rgb_img = cv2.merge([r,g,b])
                new_array=cv2.resize(rgb_img,(img_size,img_size))
                training_data.append([new_array, class_num])
                j=j+1
                # print("j2 = ",j)
            except Exception as e:
                pass
        
create_train_data()

print(np.shape(training_data))

X = []
y = []
depth = 8
indices = [0, 1, 2, 3 ,4 ,5 ,6 ,7]
for features, label in training_data:
    X.append(features)
    y.append(label)
   
X = np.array(X).reshape(-1,img_size,img_size,3)
y1 = np.array(y).reshape(-1,1)


from numpy import argmax
from keras.utils import to_categorical

# one hot encode
y2 = to_categorical(y1)

print(np.shape(X))
print(np.shape(y2))

print(y2[0,:])

import pandas as pd
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y2,test_size=0.12, stratify = y2)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

from collections import Counter
itemCt = Counter(y)
maxCt = float(max(itemCt.values()))
cw = {clsID : maxCt/numImg for clsID, numImg in itemCt.items()}

print(cw)

print(np.unique(y_train, axis=0,return_counts=True))

print(np.unique(y_test, axis=0,return_counts=True))

from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input
from tensorflow.keras import regularizers

# create the base pre-trained model

input_tensor = Input(shape=(500, 500, 3))
base_model = InceptionV3(input_tensor=input_tensor,input_shape=(500,500,3), weights='imagenet', include_top=False, classes=8)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.0001))(x)
x = tf.keras.layers.Dropout(0.4)(x)
# and a logistic layer -- let's say we have 200 classes
predictions = Dense(8, activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional InceptionV3 layers
for layer in base_model.layers:
    layer.trainable = False
    
# compile the model (should be done *after* setting layers to non-trainable)
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

model.summary()

# compile the model (should be done *after* setting layers to non-trainable)
#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

checkpoint_path = "training_1_1/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

#model.load_weights(checkpoint_path)

train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    width_shift_range=0.2)

validation_datagen = ImageDataGenerator(
    rescale=1. / 255)


history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=32),
                              steps_per_epoch=len(X_train) / 32,
                              epochs=15,
                              validation_data=validation_datagen.flow(X_test, y_test, batch_size=32),
                              validation_steps=len(X_test) / 32, 
                              class_weight = cw,
                              callbacks=[cp_callback])

# let's visualize layer names and layer indices to see how many layers
# we should freeze:
for i, layer in enumerate(base_model.layers):
   print(i, layer.name)

# we chose to train the top 2 inception blocks, i.e. we will freeze
# the first 249 layers and unfreeze the rest:
for layer in model.layers[:197]:
   layer.trainable = False
for layer in model.layers[197:]:
   layer.trainable = True


# we need to recompile the model for these modifications to take effect
# we use SGD with a low learning rate
#from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Nadam
model.compile(optimizer=Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['acc'])

# we train our model again (this time fine-tuning the top 2 inception blocks
# alongside the top Dense layers

train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    width_shift_range=0.2)

validation_datagen = ImageDataGenerator(
    rescale=1. / 255)


history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=32),
                              steps_per_epoch=len(X_train) / 32,
                              epochs=40,
                              validation_data=validation_datagen.flow(X_test, y_test, batch_size=32),
                              validation_steps=len(X_test) / 32, 
                              class_weight = cw,
                              callbacks=[cp_callback])

model.save('/content/drive/My Drive/Project_Data/rf_net_inceptionV3_mODIFIED.h5')

